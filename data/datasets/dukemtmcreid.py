# encoding: utf-8
"""
@author:  liaoxingyu
@contact: liaoxingyu2@jd.com
"""

import glob
import re
import urllib
import zipfile

import os.path as osp

from utils.iotools import mkdir_if_missing
from .bases import BaseImageDataset
import json


class DukeMTMCreID(BaseImageDataset):
    """
    DukeMTMC-reID
    Reference:
    1. Ristani et al. Performance Measures and a Data Set for Multi-Target, Multi-Camera Tracking. ECCVW 2016.
    2. Zheng et al. Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in vitro. ICCV 2017.
    URL: https://github.com/layumi/DukeMTMC-reID_evaluation

    Dataset statistics:
    # identities: 1404 (train + query)
    # images:16522 (train) + 2228 (query) + 17661 (gallery)
    # cameras: 8
    """
    dataset_dir = 'dukemtmc-reid'

    def __init__(self, root='/home/haoluo/data', train_anno = 1, verbose=True, **kwargs):
        super(DukeMTMCreID, self).__init__()
        self.dataset_dir = root
        self.dataset_url = 'http://vision.cs.duke.edu/DukeMTMC/data/misc/DukeMTMC-reID.zip'
        self.train_dir = osp.join(self.dataset_dir, 'DukeMTMC-reID/bounding_box_train')
        self.query_dir = osp.join(self.dataset_dir, 'DukeMTMC-reID/query')
        self.gallery_dir = osp.join(self.dataset_dir, 'DukeMTMC-reID/bounding_box_test')

        # self._download_data()
        # self._check_before_run()

        self.root = "/raid/home/henrayzhao/person_search/dataset/multi_person/prw"
        # self.multi_person_training_info2()
        self.train_anno = train_anno

        train = self.process_dir_train(relabel=True)
        query = self._process_dir(self.query_dir, relabel=False)
        gallery = self._process_dir(self.gallery_dir, relabel=False)

        # if verbose:
        #     print("=> DukeMTMC-reID loaded")
        #     self.print_dataset_statistics(train, query, gallery)

        self.train = train
        self.query = query
        self.gallery = gallery

        self.num_train_pids, self.num_train_imgs, self.num_train_cams = self.get_imagedata_info_train(self.train)
        self.num_query_pids, self.num_query_imgs, self.num_query_cams = self.get_imagedata_info(self.query)
        self.num_gallery_pids, self.num_gallery_imgs, self.num_gallery_cams = self.get_imagedata_info(self.gallery)

    def _download_data(self):
        if osp.exists(self.dataset_dir):
            print("This dataset has been downloaded.")
            return

        print("Creating directory {}".format(self.dataset_dir))
        mkdir_if_missing(self.dataset_dir)
        fpath = osp.join(self.dataset_dir, osp.basename(self.dataset_url))

        print("Downloading DukeMTMC-reID dataset")
        urllib.request.urlretrieve(self.dataset_url, fpath)

        print("Extracting files")
        zip_ref = zipfile.ZipFile(fpath, 'r')
        zip_ref.extractall(self.dataset_dir)
        zip_ref.close()

    def _check_before_run(self):
        """Check if all files are available before going deeper"""
        if not osp.exists(self.dataset_dir):
            raise RuntimeError("'{}' is not available".format(self.dataset_dir))
        if not osp.exists(self.train_dir):
            raise RuntimeError("'{}' is not available".format(self.train_dir))
        if not osp.exists(self.query_dir):
            raise RuntimeError("'{}' is not available".format(self.query_dir))
        if not osp.exists(self.gallery_dir):
            raise RuntimeError("'{}' is not available".format(self.gallery_dir))

    def _process_dir(self, dir_path, relabel=False):
        img_paths = glob.glob(osp.join(dir_path, '*.jpg'))
        pattern = re.compile(r'([-\d]+)_c(\d)')

        pid_container = set()
        for img_path in img_paths:
            pid, _ = map(int, pattern.search(img_path).groups())
            pid_container.add(pid)
        pid2label = {pid: label for label, pid in enumerate(pid_container)}

        dataset = []
        for img_path in img_paths:
            pid, camid = map(int, pattern.search(img_path).groups())
            assert 1 <= camid <= 8
            camid -= 1  # index starts from 0
            if relabel: pid = pid2label[pid]
            dataset.append((img_path, pid, camid))
            if 'query' in dir_path and len(dataset) >= 300:
                break

        return dataset

    def get_imagedata_info_train(self, data):

        pids, cams = [], []
        for _, _, pid, camid, pid2, pos_neg in data:
            pids += [pid]
            pids += [pid2]
            cams += [camid]
        pids = set(pids)
        cams = set(cams)
        num_pids = len(pids)
        num_cams = len(cams)
        num_imgs = len(data)
        return num_pids, num_imgs, num_cams

    def process_dir_train(self, relabel=True):
        root = "/raid/home/henrayzhao/person_search/dataset/person_search/prw"
        anno_path = osp.join(root, "training_box", "training_box.json")
        with open(anno_path, 'r+') as f:
            all_anno = json.load(f)

        pid_container = set()
        for img_name, pid in all_anno.items():
            pid_container.add(pid)
        pid2label = {int(pid): label for label, pid in enumerate(pid_container)}

        new_anno_path = osp.join(self.root, "pair_pos_unary" + str(self.train_anno) + ".json")
        with open(new_anno_path, 'r+') as f:
            all_anno = json.load(f)
        data = []

        img_root1 = "/raid/home/henrayzhao/person_search/dataset/multi_person/prw/hard_gallery_train/image"
        img_root2 = "/raid/home/henrayzhao/person_search/dataset/multi_person/prw/train_gt/image"

        for one_pair in all_anno:
            # print(one_pair)
            hard_imgname = one_pair[0]
            query_train_imgname1 = one_pair[1]
            pid1 = one_pair[2]
            query_train_imgname2 = one_pair[3]
            pid2 = one_pair[4]
            camera_id = one_pair[5]
            if relabel:
                pid1 = pid2label[pid1]
                pid2 = pid2label[pid2]
            hard_imgname_path = osp.join(img_root1, hard_imgname)
            query_train_path1 = osp.join(img_root2, query_train_imgname1)
            query_train_path2 = osp.join(img_root2, query_train_imgname2)
            new_anno = [hard_imgname_path, query_train_path1, pid1, query_train_path2, pid2, camera_id]
            data.append(new_anno)
        return data
